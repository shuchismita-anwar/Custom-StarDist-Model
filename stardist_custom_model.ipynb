{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for training\n",
    "import tifffile\n",
    "from stardist.models import Config2D, StarDist2D\n",
    "from csbdeep.utils import Path, normalize\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check if GPU is available\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28 training images.\n"
     ]
    }
   ],
   "source": [
    "# Paths to your training data\n",
    "data_path = 'D:/stardist_segmentation/original'  # Update with your path\n",
    "\n",
    "# Load and normalize your data\n",
    "X_train_files = sorted(Path(data_path).glob('*.tif'))  # Your image file naming pattern\n",
    "\n",
    "if len(X_train_files) == 0:\n",
    "    raise ValueError(\"No training images found. Please check the paths and ensure there are .tif files in the directories.\")\n",
    "\n",
    "print(f'Found {len(X_train_files)} training images.')\n",
    "\n",
    "X_train = [normalize(tifffile.imread(file)) for file in X_train_files]\n",
    "Y_train = [tifffile.imread(file) for file in X_train_files]  # Using the same images as pseudo-labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_patches(X, Y, patch_size=(256, 256), num_patches=100):\n",
    "    patches_X = []\n",
    "    patches_Y = []\n",
    "    \n",
    "    for _ in range(num_patches):\n",
    "        idx = random.randint(0, len(X) - 1)\n",
    "        img = X[idx]\n",
    "        lbl = Y[idx]\n",
    "        \n",
    "        h, w = img.shape[:2]\n",
    "        ph, pw = patch_size\n",
    "        \n",
    "        if h < ph or w < pw:\n",
    "            continue\n",
    "        \n",
    "        y = random.randint(0, h - ph)\n",
    "        x = random.randint(0, w - pw)\n",
    "        \n",
    "        patch_X = img[y:y+ph, x:x+pw]\n",
    "        patch_Y = lbl[y:y+ph, x:x+pw]\n",
    "        \n",
    "        patches_X.append(patch_X)\n",
    "        patches_Y.append(patch_Y)\n",
    "    \n",
    "    return np.array(patches_X), np.array(patches_Y)\n",
    "\n",
    "# Create patches\n",
    "X_patches, Y_patches = generate_patches(X_train, Y_train, patch_size=(256, 256), num_patches=500)  # Reducing the number of patches to speed up\n",
    "\n",
    "if len(X_patches) == 0 or len(Y_patches) == 0:\n",
    "    raise ValueError(\"No patches generated. Please check the input images and patch size.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model configuration\n",
    "conf = Config2D(\n",
    "    n_rays=32,\n",
    "    grid=(1, 1),\n",
    "    use_gpu=False,  # Ensure GPU usage\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "base_model.py (198): output path for model already exists, files may be overwritten: D:\\stardist_segmentation\\models\\stardist_custom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default values: prob_thresh=0.5, nms_thresh=0.4.\n",
      "Epoch 1 started.\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1001s\u001b[0m 10s/step - dist_dist_iou_metric: 0.1766 - dist_relevant_mae: 4.1032 - dist_relevant_mse: 209.8510 - loss: 1.4095 - prob_kld: 0.1716 - val_dist_dist_iou_metric: 0.3874 - val_dist_relevant_mae: 3.2889 - val_dist_relevant_mse: 167.3624 - val_loss: 1.1371 - val_prob_kld: 0.0647 - learning_rate: 3.0000e-04\n",
      "\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Epoch 1 completed in 2067.16 seconds.\n",
      "Epoch 2 started.\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m924s\u001b[0m 9s/step - dist_dist_iou_metric: 0.3939 - dist_relevant_mae: 2.8995 - dist_relevant_mse: 126.1358 - loss: 1.0587 - prob_kld: 0.0631 - val_dist_dist_iou_metric: 0.4234 - val_dist_relevant_mae: 3.1555 - val_dist_relevant_mse: 155.1654 - val_loss: 1.1041 - val_prob_kld: 0.0583 - learning_rate: 3.0000e-04\n",
      "\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Epoch 2 completed in 2021.44 seconds.\n",
      "Epoch 3 started.\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m896s\u001b[0m 9s/step - dist_dist_iou_metric: 0.4293 - dist_relevant_mae: 3.2127 - dist_relevant_mse: 153.9041 - loss: 1.1155 - prob_kld: 0.0586 - val_dist_dist_iou_metric: 0.4572 - val_dist_relevant_mae: 3.2236 - val_dist_relevant_mse: 161.7546 - val_loss: 1.1109 - val_prob_kld: 0.0516 - learning_rate: 3.0000e-04\n",
      "\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Epoch 3 completed in 1943.92 seconds.\n",
      "Epoch 4 started.\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m920s\u001b[0m 9s/step - dist_dist_iou_metric: 0.4178 - dist_relevant_mae: 3.4271 - dist_relevant_mse: 176.2477 - loss: 1.1594 - prob_kld: 0.0595 - val_dist_dist_iou_metric: 0.4570 - val_dist_relevant_mae: 3.1489 - val_dist_relevant_mse: 157.2030 - val_loss: 1.0969 - val_prob_kld: 0.0524 - learning_rate: 3.0000e-04\n",
      "\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Epoch 4 completed in 1966.38 seconds.\n",
      "Epoch 5 started.\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m927s\u001b[0m 9s/step - dist_dist_iou_metric: 0.4591 - dist_relevant_mae: 2.9137 - dist_relevant_mse: 128.9008 - loss: 1.0544 - prob_kld: 0.0544 - val_dist_dist_iou_metric: 0.4751 - val_dist_relevant_mae: 3.1470 - val_dist_relevant_mse: 157.1407 - val_loss: 1.0949 - val_prob_kld: 0.0509 - learning_rate: 3.0000e-04\n",
      "\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Epoch 5 completed in 1970.65 seconds.\n",
      "Average time per epoch: 1993.91 seconds.\n",
      "Estimated total time for 400 epochs: 221.55 hours.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the StarDist model\n",
    "model = StarDist2D(conf, name='stardist_custom', basedir='models')\n",
    "\n",
    "# Custom training loop to print the epoch number and measure time\n",
    "epochs = 5  # Measure time for first 5 epochs\n",
    "total_time = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch + 1} started.')\n",
    "    start_time = time.time()\n",
    "    model.train(X_patches, Y_patches, validation_data=(X_patches, Y_patches), epochs=1)\n",
    "    epoch_time = time.time() - start_time\n",
    "    total_time += epoch_time\n",
    "    print(f'Epoch {epoch + 1} completed in {epoch_time:.2f} seconds.')\n",
    "\n",
    "average_epoch_time = total_time / epochs\n",
    "print(f'Average time per epoch: {average_epoch_time:.2f} seconds.')\n",
    "estimated_total_time = average_epoch_time * 400\n",
    "print(f'Estimated total time for 400 epochs: {estimated_total_time / 3600:.2f} hours.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for segmentation\n",
    "import os\n",
    "import tifffile\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from stardist.models import StarDist2D\n",
    "from csbdeep.utils import normalize\n",
    "from stardist.plot import render_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the images\n",
    "input_dir = 'D:/stardist_segmentation/original'\n",
    "output_dir = 'D:/stardist_segmentation/segmentation_results'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network weights from 'weights_best.h5'.\n",
      "Couldn't load thresholds from 'thresholds.json', using default values. (Call 'optimize_thresholds' to change that.)\n",
      "Using default values: prob_thresh=0.5, nms_thresh=0.4.\n"
     ]
    }
   ],
   "source": [
    "# Load the custom StarDist model\n",
    "model = StarDist2D(None, name='stardist_custom', basedir='models')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved segmentation for Muc1_Ecad_SPC_x20_2_XY10_00001_CH3.tif to D:/stardist_segmentation/segmentation_results\\Muc1_Ecad_SPC_x20_2_XY10_00001_CH3_segmentation.png\n",
      "Saved segmentation for Muc1_Ecad_SPC_x20_2_XY10_00002_CH3.tif to D:/stardist_segmentation/segmentation_results\\Muc1_Ecad_SPC_x20_2_XY10_00002_CH3_segmentation.png\n",
      "Saved segmentation for Muc1_Ecad_SPC_x20_2_XY10_00007_CH3.tif to D:/stardist_segmentation/segmentation_results\\Muc1_Ecad_SPC_x20_2_XY10_00007_CH3_segmentation.png\n",
      "Saved segmentation for Muc1_Ecad_SPC_x20_2_XY10_00008_CH3.tif to D:/stardist_segmentation/segmentation_results\\Muc1_Ecad_SPC_x20_2_XY10_00008_CH3_segmentation.png\n",
      "Saved segmentation for Muc1_Ecad_SPC_x20_2_XY10_00009_CH3.tif to D:/stardist_segmentation/segmentation_results\\Muc1_Ecad_SPC_x20_2_XY10_00009_CH3_segmentation.png\n",
      "Saved segmentation for Muc1_Ecad_SPC_x20_2_XY10_00010_CH3.tif to D:/stardist_segmentation/segmentation_results\\Muc1_Ecad_SPC_x20_2_XY10_00010_CH3_segmentation.png\n",
      "Saved segmentation for Muc1_Ecad_SPC_x20_2_XY10_00011_CH3.tif to D:/stardist_segmentation/segmentation_results\\Muc1_Ecad_SPC_x20_2_XY10_00011_CH3_segmentation.png\n",
      "Saved segmentation for Muc1_Ecad_SPC_x20_2_XY10_00012_CH3.tif to D:/stardist_segmentation/segmentation_results\\Muc1_Ecad_SPC_x20_2_XY10_00012_CH3_segmentation.png\n",
      "Saved segmentation for Muc1_Ecad_SPC_x20_2_XY10_00013_CH3.tif to D:/stardist_segmentation/segmentation_results\\Muc1_Ecad_SPC_x20_2_XY10_00013_CH3_segmentation.png\n",
      "Saved segmentation for Muc1_Ecad_SPC_x20_2_XY10_00014_CH3.tif to D:/stardist_segmentation/segmentation_results\\Muc1_Ecad_SPC_x20_2_XY10_00014_CH3_segmentation.png\n",
      "Saved segmentation for Muc1_Ecad_SPC_x20_2_XY10_00015_CH3.tif to D:/stardist_segmentation/segmentation_results\\Muc1_Ecad_SPC_x20_2_XY10_00015_CH3_segmentation.png\n",
      "Saved segmentation for Muc1_Ecad_SPC_x20_2_XY10_00016_CH3.tif to D:/stardist_segmentation/segmentation_results\\Muc1_Ecad_SPC_x20_2_XY10_00016_CH3_segmentation.png\n",
      "Saved segmentation for Muc1_Ecad_SPC_x20_2_XY10_00017_CH3.tif to D:/stardist_segmentation/segmentation_results\\Muc1_Ecad_SPC_x20_2_XY10_00017_CH3_segmentation.png\n",
      "Saved segmentation for Muc1_Ecad_SPC_x20_2_XY10_00019_CH3.tif to D:/stardist_segmentation/segmentation_results\\Muc1_Ecad_SPC_x20_2_XY10_00019_CH3_segmentation.png\n",
      "Saved segmentation for Muc1_Ecad_SPC_x20_2_XY10_00020_CH3.tif to D:/stardist_segmentation/segmentation_results\\Muc1_Ecad_SPC_x20_2_XY10_00020_CH3_segmentation.png\n",
      "Saved segmentation for Muc1_Ecad_SPC_x20_2_XY10_00021_CH3.tif to D:/stardist_segmentation/segmentation_results\\Muc1_Ecad_SPC_x20_2_XY10_00021_CH3_segmentation.png\n",
      "Saved segmentation for Muc1_Ecad_SPC_x20_2_XY10_00022_CH3.tif to D:/stardist_segmentation/segmentation_results\\Muc1_Ecad_SPC_x20_2_XY10_00022_CH3_segmentation.png\n",
      "Saved segmentation for Muc1_Ecad_SPC_x20_2_XY10_00023_CH3.tif to D:/stardist_segmentation/segmentation_results\\Muc1_Ecad_SPC_x20_2_XY10_00023_CH3_segmentation.png\n",
      "Saved segmentation for Muc1_Ecad_SPC_x20_2_XY10_00026_CH3.tif to D:/stardist_segmentation/segmentation_results\\Muc1_Ecad_SPC_x20_2_XY10_00026_CH3_segmentation.png\n",
      "Saved segmentation for Muc1_Ecad_SPC_x20_2_XY10_00027_CH3.tif to D:/stardist_segmentation/segmentation_results\\Muc1_Ecad_SPC_x20_2_XY10_00027_CH3_segmentation.png\n",
      "Saved segmentation for Muc1_Ecad_SPC_x20_2_XY10_00028_CH3.tif to D:/stardist_segmentation/segmentation_results\\Muc1_Ecad_SPC_x20_2_XY10_00028_CH3_segmentation.png\n",
      "Saved segmentation for Muc1_Ecad_SPC_x20_2_XY10_00029_CH3.tif to D:/stardist_segmentation/segmentation_results\\Muc1_Ecad_SPC_x20_2_XY10_00029_CH3_segmentation.png\n",
      "Saved segmentation for Muc1_Ecad_SPC_x20_2_XY10_00030_CH3.tif to D:/stardist_segmentation/segmentation_results\\Muc1_Ecad_SPC_x20_2_XY10_00030_CH3_segmentation.png\n",
      "Saved segmentation for Muc1_Ecad_SPC_x20_2_XY10_00031_CH3.tif to D:/stardist_segmentation/segmentation_results\\Muc1_Ecad_SPC_x20_2_XY10_00031_CH3_segmentation.png\n",
      "Saved segmentation for Muc1_Ecad_SPC_x20_2_XY10_00033_CH3.tif to D:/stardist_segmentation/segmentation_results\\Muc1_Ecad_SPC_x20_2_XY10_00033_CH3_segmentation.png\n",
      "Saved segmentation for Muc1_Ecad_SPC_x20_2_XY10_00034_CH3.tif to D:/stardist_segmentation/segmentation_results\\Muc1_Ecad_SPC_x20_2_XY10_00034_CH3_segmentation.png\n",
      "Saved segmentation for Muc1_Ecad_SPC_x20_2_XY10_00039_CH3.tif to D:/stardist_segmentation/segmentation_results\\Muc1_Ecad_SPC_x20_2_XY10_00039_CH3_segmentation.png\n",
      "Saved segmentation for Muc1_Ecad_SPC_x20_2_XY10_00040_CH3.tif to D:/stardist_segmentation/segmentation_results\\Muc1_Ecad_SPC_x20_2_XY10_00040_CH3_segmentation.png\n"
     ]
    }
   ],
   "source": [
    "# Process each image in the directory\n",
    "for image_name in os.listdir(input_dir):\n",
    "    if image_name.endswith('.tif') or image_name.endswith('.tiff'):\n",
    "        image_path = os.path.join(input_dir, image_name)\n",
    "        img = tifffile.imread(image_path)\n",
    "\n",
    "        # Normalize the image\n",
    "        img_normalized = normalize(img, 1, 99.8, axis=(0, 1))\n",
    "\n",
    "        # Predict instances with default parameters\n",
    "        labels, details = model.predict_instances(img_normalized)\n",
    "\n",
    "        # Post-processing using advanced morphological operations\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        labels_post = cv2.morphologyEx(labels.astype(np.uint8), cv2.MORPH_CLOSE, kernel)\n",
    "        labels_post = cv2.morphologyEx(labels_post, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        # Additional post-processing (dilation followed by erosion)\n",
    "        labels_post = cv2.dilate(labels_post, kernel, iterations=1)\n",
    "        labels_post = cv2.erode(labels_post, kernel, iterations=1)\n",
    "\n",
    "        # Save the results\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title('Input Image')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(render_label(labels_post, img=img))\n",
    "        plt.title('Prediction + Input Overlay')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        output_path = os.path.join(output_dir, f'{os.path.splitext(image_name)[0]}_segmentation.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "\n",
    "        print(f'Saved segmentation for {image_name} to {output_path}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stardist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
